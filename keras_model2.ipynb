{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from ca_funcs import make_glider, make_game_of_life\n",
    "from utils import *\n",
    "from train_ca import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 14\n",
    "wspan= 100\n",
    "hspan = 100\n",
    "nhood = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(np.random.choice([0,1], (1000, wspan, hspan), p=[.5,.5]), tf.float32)\n",
    "gol = make_game_of_life()\n",
    "Y_train = gol(tf.convert_to_tensor(X_train, tf.float32))\n",
    "\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "Y_train = Y_train[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data\n",
    "data = np.load(\"../../data/d0.npy\")\n",
    "for i in range(1,10):\n",
    "    temp_data = np.load(\"../../data/d\"+str(i)+\".npy\")\n",
    "    data=np.concatenate((data,temp_data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145000, 2, 100, 100, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data=data.reshape(len(data),2,100,100,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data[:,0], data[:,1],test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_onehot = tf.squeeze(tf.one_hot(tf.cast(Y_train, tf.int32), num_classes))\n",
    "Y_test_onehot = tf.squeeze(tf.one_hot(tf.cast(Y_test, tf.int32), num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save train test arrays\n",
    "np.save('X_train.npy',X_train)\n",
    "np.save('X_test.npy',X_test)\n",
    "np.save('Y_train_onehot.npy',Y_train_onehot)\n",
    "np.save('Y_test_onehot.npy',Y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### load train and test arrays\n",
    "#80\n",
    "#X_train = np.load('X_train.npy')\n",
    "#20\n",
    "X_train = np.load('X_test.npy')\n",
    "#20\n",
    "#X_test = np.load('X_test.npy')\n",
    "#80\n",
    "#X_test = np.load('X_train.npy')\n",
    "#80\n",
    "#Y_train_onehot = np.load('Y_train_onehot.npy')\n",
    "#20\n",
    "#Y_train_onehot = np.load('Y_test_onehot.npy')\n",
    "#20\n",
    "#Y_test_onehot = np.load('Y_test_onehot.npy')\n",
    "#80\n",
    "#Y_test_onehot = np.load('Y_train_onehot.npy')\n",
    "#80\n",
    "#Y_train = np.load('Y_train.npy')\n",
    "#20\n",
    "Y_train = np.load('Y_test.npy')\n",
    "#80\n",
    "#Y_test = np.load('Y_train.npy')\n",
    "#20\n",
    "#Y_test = np.load('Y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 100, 100, 100)     1000      \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 100, 100, 100)     10100     \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 100, 100, 1)       101       \n",
      "=================================================================\n",
      "Total params: 112,201\n",
      "Trainable params: 112,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### Define and build model\n",
    "tf.random.set_seed(0)\n",
    "layer_dims = [100, 100, 100]\n",
    "loss = lambda x, y : tf.keras.losses.MSE(x,y)\n",
    "diameter = 2*nhood+1\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer((wspan, hspan, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(100, kernel_size=[diameter, diameter], padding='same', \n",
    "                                 activation='relu', kernel_initializer=tf.keras.initializers.he_normal(), \n",
    "                                 bias_initializer=tf.keras.initializers.he_normal()))\n",
    "for i in range(11):\n",
    "    model.add(tf.keras.layers.Conv2D(100, kernel_size=[1,1],activation='relu', kernel_initializer=tf.keras.initializers.he_normal(), \n",
    "                                 bias_initializer=tf.keras.initializers.he_normal()))\n",
    "model.add(tf.keras.layers.Conv2D(1, kernel_size=[1,1], kernel_initializer=tf.keras.initializers.he_normal(), \n",
    "                                 bias_initializer=tf.keras.initializers.he_normal()))\n",
    "#for i in range(1, len(layer_dims)):\n",
    "#model.add(tf.keras.layers.Dense(layer_dims[i],  activation='relu',\n",
    "#                                kernel_initializer=tf.keras.initializers.he_normal(), \n",
    "#                                bias_initializer=tf.keras.initializers.he_normal()))\n",
    "#model.add(tf.keras.layers.Dense(num_classes,  activation='relu',\n",
    "#                                kernel_initializer=tf.keras.initializers.he_normal(), \n",
    "#                                bias_initializer=tf.keras.initializers.he_normal()))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=loss,metrics=['accuracy'])\n",
    "#model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-1, nesterov=True), loss=loss,metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 150\n",
    "checkpoint_filepath = 'best_working_ADAM_e-3_keras_model_2.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "232/232 [==============================] - 127s 544ms/step - loss: 9.7634 - accuracy: 0.5322 - val_loss: 5.4115 - val_accuracy: 0.5487\n",
      "Epoch 2/150\n",
      "232/232 [==============================] - 126s 542ms/step - loss: 5.4608 - accuracy: 0.5599 - val_loss: 5.0406 - val_accuracy: 0.5596\n",
      "Epoch 3/150\n",
      " 73/232 [========>.....................] - ETA: 1:18 - loss: 4.7411 - accuracy: 0.5808"
     ]
    }
   ],
   "source": [
    "#### Run training\n",
    "train_history1 = model.fit(x=X_train, y=Y_train, epochs=150, batch_size=100,shuffle = True,verbose=1,validation_split=0.2,callbacks=[model_checkpoint_callback])\n",
    "#train_history = model.fit(x=X_train, y=Y_train, epochs=EPOCHS, batch_size=28,shuffle = True,verbose=1,validation_split=0.2,callbacks=[model_checkpoint_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Load model\n",
    "#file='best_working_SGD_nesterov_e-1_kerastemp.h5'\n",
    "file='best_working_SGD_nesterov_e-1_keras_model_2.h5'\n",
    "model.load_weights(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29000, 100, 100, 1)\n",
      "(29000, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_train=np.reshape(Y_train,(len(Y_train),100,100,1))\n",
    "print(Y_train.shape)\n",
    "X_train=np.reshape(X_train,(len(X_train),100,100,1))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = train_history.history['loss']+train_history1.history['loss'] \n",
    "val_loss = train_history.history['val_loss']+train_history1.history['val_loss']\n",
    "plt.plot(train_loss, 'k',label=\"training loss\",color='green')\n",
    "plt.plot(val_loss, 'k',label=\"validation loss\",color='red')\n",
    "plt.xlabel('epochs', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625/3625 [==============================] - 186s 45ms/step - loss: 0.1317 - accuracy: 0.9502\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the model\n",
    "results = model.evaluate(X_test, Y_test_onehot, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test accuracy :  [0.1317313313484192, 0.9501531720161438]\n"
     ]
    }
   ],
   "source": [
    "print(\"test loss, test accuracy : \",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[..., tf.newaxis]\n",
    "Y_test = Y_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logit_to_pred(model(X_test[:13]), shape=(-1, wspan, hspan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot results\n",
    "\n",
    "## Generate testing data\n",
    "#X_test = tf.convert_to_tensor(np.moveaxis(np.dstack([make_glider(10), make_glider(10)]), 2, 0), tf.float32)\n",
    "# X_test = tf.convert_to_tensor(make_glider(10), tf.float32)[tf.newaxis, ...]\n",
    "#Y_test = gol(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "temp=1\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(tf.squeeze(X_test[temp]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Input\")\n",
    "print('input',X_test[temp].reshape(100,100))\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(tf.squeeze(Y_test[temp]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Expected Output\")\n",
    "print('expected',Y_test[temp].reshape(100,100))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(tf.squeeze(Y_pred[temp]))\n",
    "plt.axis('off')\n",
    "plt.title(\"Observed Output\")\n",
    "print('obswered',Y_pred[temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save and load a model\n",
    "model.save('keras_model.h5')\n",
    "#del model\n",
    "#model = tf.keras.models.load_model('path_to_my_model.h5', custom_objects={'Wraparound2D': Wraparound2D})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show activation patterns of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function(inp, outputs)   # evaluation function\n",
    "\n",
    "layer_outs = functor([X_test, 1.])\n",
    "\n",
    "\n",
    "\n",
    "# Plot activations of different neurons in different layers \n",
    "all_layer_activations = list()\n",
    "\n",
    "min_max_scaler = lambda x : (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "# min_max_scaler = lambda x : (x - np.mean(x))\n",
    "for j in range(1, 5):\n",
    "    if j==1:\n",
    "        layer_im = np.hstack([min_max_scaler(layer_outs[1][0][..., i]) for i in range(10)])\n",
    "    else:\n",
    "        pattern = np.reshape(layer_outs[j][0], (wspan, hspan, -1))\n",
    "        layer_im = np.hstack([min_max_scaler(pattern[..., i]) for i in range(10)])\n",
    "    all_layer_activations.append(layer_im)\n",
    "\n",
    "        \n",
    "plt.figure()\n",
    "plt.imshow(np.vstack(all_layer_activations))\n",
    "plt.title(\"Activations of hidden layers given \\\"Glider\\\" input\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(np.dstack(model.layers[1].weights[0].numpy())))\n",
    "plt.title(\"Convolutional filters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
